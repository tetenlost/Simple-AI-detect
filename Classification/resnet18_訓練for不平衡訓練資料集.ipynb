{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# resnet18 分類器模型訓練\n",
        "\n",
        "使用pytorch提供之模型進行訓練\n",
        "\n",
        "\n",
        "*   在\"常見CNN分類模型\"中展示了如何使用pytorch提供之模型進行預測(RESNET、VGG等)，但在實際應用上卻較難與需求吻合(如產品瑕疵類別)，因此此篇將使用\"遷移學習\"對模型在訓練，使其可以分類出我們想要之類別\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DBy_UC1ZArkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 下載分類影像\n",
        "\n",
        "\n",
        "*   在製作訓練檔上需要將圖片放置成以下特定格式\n",
        "\n",
        "(此篇教學已先分好了，按下執行就完事)\n",
        "\n",
        "    ```\n",
        "    |-train <- 這是訓練集資料夾\n",
        "     |-cls1 <-類別1的圖像資料夾\n",
        "      |-0000.jpg <-類別1的圖像(圖像名稱可隨意)\n",
        "     |-cls2\n",
        "     .\n",
        "    |-val <-這是測試集資料夾\n",
        "     |-cls1 <-類別1的圖像資料夾\n",
        "      |-0001.jpg\n",
        "     |-cls2\n",
        "    ```"
      ],
      "metadata": {
        "id": "KyqrIC-dGgUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hjJkOirSAj1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e732eafa-73bd-4b7c-a85f-7784447b92d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'demo_training_data'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Total 114 (delta 0), reused 0 (delta 0), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (114/114), 2.17 MiB | 23.68 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tetenlost/demo_training_data.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "K2YY-hPxFHO7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 刪除95％資料，故意造成資料不平衡"
      ],
      "metadata": {
        "id": "vfJpGoQ9oA_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "def show_file(a_path):\n",
        "    for item in os.listdir(a_path):\n",
        "        # 构建子文件夹/文件的完整路径\n",
        "        item_path = os.path.join(a_path, item)\n",
        "        # 判断是否为文件夹\n",
        "        if os.path.isdir(item_path):\n",
        "            # 获取文件夹内文件数量\n",
        "            files = len(os.listdir(item_path))\n",
        "            # 打印结果\n",
        "            print(\"{}内有{}个文件。\".format(item, files))\n",
        "show_file('/content/demo_training_data/train/')\n",
        "# 設定要刪除的檔案比例\n",
        "delete_percent = 0.95\n",
        "\n",
        "# 設定資料夾路徑\n",
        "folder_path = \"/content/demo_training_data/train/cardboard\"\n",
        "\n",
        "# 取得資料夾內所有檔案列表\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# 計算要刪除的檔案數量\n",
        "num_files_to_delete = int(delete_percent * len(file_list))\n",
        "\n",
        "# 隨機選取要刪除的檔案\n",
        "files_to_delete = random.sample(file_list, num_files_to_delete)\n",
        "\n",
        "# 刪除選取的檔案\n",
        "for file_name in files_to_delete:\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    os.remove(file_path)\n",
        "show_file('/content/demo_training_data/train/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "328nnksQwAAd",
        "outputId": "fd3563ef-4ce5-4040-f738-92c116d10fae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glass内有40个文件。\n",
            "cardboard内有40个文件。\n",
            "glass内有40个文件。\n",
            "cardboard内有2个文件。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 宣告資料讀取函式\n",
        "\n",
        "* 將資料集打包，並做影像處理，方便後續訓練"
      ],
      "metadata": {
        "id": "IdqflgGCGk8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_data(path,batchsize):\n",
        "    #宣告訓練集影像處理方式\n",
        "    train_transform = transforms.Compose([\n",
        "                        #圖像縮放至224*224\n",
        "                        transforms.Resize((224,224)),\n",
        "                        #影像隨機水平翻轉(機率50%)\n",
        "                        transforms.RandomHorizontalFlip(p=0.5),\n",
        "                        #影像隨機垂直翻轉(機率50%) \n",
        "                        transforms.RandomVerticalFlip(p=0.5),\n",
        "                        #影像之亮度、色相、飽和度隨機轉換\n",
        "                        transforms.ColorJitter(hue=0.3),\n",
        "                        #影像旋轉、平移、縮放\n",
        "                        transforms.RandomAffine(degrees=20, shear=(30,30), translate=(0.2, 0.2)),\n",
        "                        #將影像轉換為pytorch格式\n",
        "                        transforms.ToTensor(),\n",
        "                        #資料標準化至(-1,1)，為了更好的訓練\n",
        "                        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "                        ])\n",
        "    #宣告測試集影像處理方式\n",
        "    val_transform = transforms.Compose([\n",
        "                        #圖像縮放至224*224\n",
        "                        transforms.Resize((224,224)),\n",
        "                        #將影像轉換為pytorch格式\n",
        "                        transforms.ToTensor(),\n",
        "                        #資料標準化至(-1,1)，為了更好的訓練\n",
        "                        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "                        ])\n",
        "    #使用ImageFolder將圖片與類別作匹配，並添加影像處理\n",
        "    train_datasets = datasets.ImageFolder(os.path.join(path, 'train'), train_transform)\n",
        "    val_datasets = datasets.ImageFolder(os.path.join(path, 'val'), val_transform)\n",
        "    #製作Dataloader，將訓練/測試拆分為batch(如batch_size=16，就是將訓練/測試每16張做為一個batch)\n",
        "    train_dataloaders = torch.utils.data.DataLoader(train_datasets, batch_size=batchsize,shuffle=True, num_workers=4)\n",
        "    val_dataloaders = torch.utils.data.DataLoader(val_datasets, batch_size=batchsize,shuffle=True, num_workers=4)\n",
        "    dataset_sizes={\n",
        "            'train':len(train_datasets),\n",
        "            'val':len(val_datasets)\n",
        "            }\n",
        "    return train_dataloaders,val_dataloaders,dataset_sizes"
      ],
      "metadata": {
        "id": "Pngfj5waJ5WV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 宣告訓練程式"
      ],
      "metadata": {
        "id": "lvDQGdyJMnOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_d, val_d, dataset_sizes, criterion, optimizer, scheduler,device, num_epochs=25):\n",
        "    #計時\n",
        "    since = time.time() \n",
        "    #將訓練/測試Dataloader製作成字典\n",
        "    dataloaders={\n",
        "            'train':train_d,\n",
        "            'val':val_d\n",
        "          }\n",
        "    best_acc = 0.0\n",
        "    #執行迴圈，總次數為訓練次數\n",
        "    for epoch in range(num_epochs):\n",
        "        #顯示幕前的訓練次數\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        #執行迴圈，第一次先執行訓練(train)，在執行測式(val)\n",
        "        for phase in ['train', 'val']:\n",
        "            #如果是執行訓練，開啟訓練模式\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            #如果不是，開啟測試模式  \n",
        "            else:\n",
        "                model.eval() \n",
        "            #初始化本次loss值與正確率\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            #執行迴圈，將批次資料從 dataloader中拿出來做訓練/測試\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                #將圖片放入設備中(CPU/GPU)\n",
        "                inputs = inputs.to(device)\n",
        "                #將答案放入設備中(CPU/GPU)\n",
        "                labels = labels.to(device)\n",
        "                #初始化優化器\n",
        "                optimizer.zero_grad()\n",
        "                #設定是否計算梯度(誤差方向)，關係到模型是否會學習\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #圖像放入模型中進行判定\n",
        "                    outputs = model(inputs)\n",
        "                    #選出得分最高之選項\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    #將輸出與答案比對，計算loss(誤差大小)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    #如果是訓練中，則將梯度(誤差方向)與loss(誤差大小)回傳至模型中，並更新權重\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() \n",
        "                        optimizer.step() \n",
        "                #將此批次訓練的loss(誤差大小)與正確數進行加總\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            #如果為訓練，更新學習率調整器\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            #計算該次訓練的平均正確率&loss\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            #存下最新的model\n",
        "            torch.save(model,'./last_model.pth')\n",
        "\n",
        "            #如果此次結果正確率創下歷史新高，則儲存\n",
        "            if phase == 'val' and epoch_acc >= best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model,'./best_model.pth')\n",
        "\n",
        "    #計算此次訓練浪費多少時間         \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    #顯示最好的那一次結果\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WYljv21UMneO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 宣告主程式(含訓練參數)\n",
        "* 在宣告損失函數時添加權重，可以減低資料不平衡造成的問題 "
      ],
      "metadata": {
        "id": "CHQt33NgJlrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    #宣告batch size\n",
        "    bs = 16\n",
        "    #宣告訓練資料存放點\n",
        "    path = './demo_training_data'\n",
        "    #宣告訓練次數\n",
        "    epoch = 10    \n",
        "    #取得訓練設備(CPU or GPU)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #獲取官方建構神經網路\n",
        "    model_ft = models.resnet18(pretrained=True)\n",
        "    ##以下是遷移學習\n",
        "    #查看倒數第二層餐數量\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    #將最後一層更改為我們的層(類別數更改)\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "    ##遷移學習更改部分結束\n",
        "    #將模型放入訓練設備(CPU or GPU)\n",
        "    model_ft.to(device)\n",
        "    #建立圖像資料集\n",
        "    train_d,val_d, dsl= build_data(path,bs)\n",
        "    #宣告損失函數(權重部分[1,1]->[20,1])\n",
        "    criterion = nn.CrossEntropyLoss(weight=torch.Tensor([1, 1]))\n",
        "    #宣告優化器\n",
        "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "    #宣告學習率調整器(每隔一段時間將學習率縮小，以習得更好的權重)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
        "    #將上述宣告的東西放進訓練函式中訓練\n",
        "    train_model(model_ft,train_d,val_d,dsl,criterion, optimizer_ft, exp_lr_scheduler,device, num_epochs=epoch)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "USX0EgfKNGDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ecb722-8cc3-41ea-b7c3-6f43ef1d392c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.4468 Acc: 0.8571\n",
            "val Loss: 0.9781 Acc: 0.5000\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.2254 Acc: 0.9524\n",
            "val Loss: 1.5750 Acc: 0.5000\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1839 Acc: 0.9524\n",
            "val Loss: 2.0283 Acc: 0.5000\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.2094 Acc: 0.9524\n",
            "val Loss: 2.2917 Acc: 0.5000\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.2331 Acc: 0.9524\n",
            "val Loss: 2.2953 Acc: 0.5000\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1934 Acc: 0.9524\n",
            "val Loss: 2.1458 Acc: 0.5000\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1527 Acc: 0.9524\n",
            "val Loss: 1.8911 Acc: 0.5000\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1626 Acc: 0.9524\n",
            "val Loss: 1.5826 Acc: 0.5000\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1564 Acc: 0.9524\n",
            "val Loss: 1.3364 Acc: 0.5000\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1350 Acc: 0.9524\n",
            "val Loss: 0.9915 Acc: 0.5000\n",
            "Training complete in 2m 20s\n",
            "Best val Acc: 0.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 刪除資料集\n"
      ],
      "metadata": {
        "id": "ovMa95Aeoi9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ./demo_training_data"
      ],
      "metadata": {
        "id": "dNdFxFZvoiHn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}