{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YoloV8語義分割\n",
        "語義分割與語言處裡無關，他是物件分類與物件偵測的進化型  \n",
        "物件分類->整張圖分類  \n",
        "物件偵測->圖像中物體大致定位＆分類  \n",
        "語義分割->像素級分類  \n",
        "它可以切很細，但是在影像標注時就會很hardcore"
      ],
      "metadata": {
        "id": "rfPe2OALozg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zroWa9wjcjC",
        "outputId": "e69230e3-d334-4730-cd85-39f19df11e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.201-py3-none-any.whl (644 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/644.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/644.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.7/644.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.201\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練部份我這邊就不再細講，與物件偵測步驟一樣，只需要改為使用語義分割的模型與資料即可，詳細參數請到yolov8官網查閱  \n",
        "文檔[https://docs.ultralytics.com/tasks/segment/#train](https://docs.ultralytics.com/tasks/segment/#train)  \n",
        "\n",
        "* 在訓練資料放置部份，也與物件偵測一致\n",
        "* labele格式為\n",
        "```\n",
        "<class-index> <x1> <y1> <x2> <y2> ... <xn> <yn>\n",
        "```\n",
        "後面的xy是該物件的外圍座標，舉個例子，五邊形就有五個點\n",
        "## Predict\n",
        "（似曾相似？）"
      ],
      "metadata": {
        "id": "dK8kBFNJs0rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "# Load a model\n",
        "model = YOLO('yolov8n-seg.pt')  # load an official model\n",
        "\n",
        "# Predict with the model\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBPrDrHDOmgK",
        "outputId": "7395b164-7769-459f-d453-19ae4cd340a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n",
            "100%|██████████| 6.73M/6.73M [00:00<00:00, 119MB/s]\n",
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n",
            "100%|██████████| 476k/476k [00:00<00:00, 18.9MB/s]\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 405.2ms\n",
            "Speed: 32.9ms preprocess, 405.2ms inference, 52.0ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict完之後，會產生boxes與mask，boxes中包含物件框與物體類別，mask中則包含物體的語義分割結果"
      ],
      "metadata": {
        "id": "aI1-erG3yJo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "for r in results:\n",
        "    #print(r.masks)\n",
        "    print(r.boxes)\n",
        "    print(np.shape(r.masks.xy))\n",
        "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    #im.show()  # show image\n",
        "    im.save('results.jpg')  # save image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNOtbRm6cRXd",
        "outputId": "a73a99be-3b13-4ed0-a339-6e88bb3697aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([ 0.,  0.,  0.,  5.,  0., 36.])\n",
            "conf: tensor([0.8875, 0.8518, 0.8420, 0.8066, 0.3430, 0.3350])\n",
            "data: tensor([[6.7012e+02, 3.8967e+02, 8.0949e+02, 8.7650e+02, 8.8753e-01, 0.0000e+00],\n",
            "        [4.9136e+01, 3.9597e+02, 2.4117e+02, 9.0409e+02, 8.5176e-01, 0.0000e+00],\n",
            "        [2.2319e+02, 4.0759e+02, 3.4405e+02, 8.6207e+02, 8.4200e-01, 0.0000e+00],\n",
            "        [2.4104e+00, 2.2786e+02, 8.0302e+02, 7.2062e+02, 8.0659e-01, 5.0000e+00],\n",
            "        [0.0000e+00, 5.5112e+02, 7.8029e+01, 8.7387e+02, 3.4300e-01, 0.0000e+00],\n",
            "        [6.6864e+02, 8.2284e+02, 8.1000e+02, 8.8203e+02, 3.3501e-01, 3.6000e+01]])\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (1080, 810)\n",
            "shape: torch.Size([6, 6])\n",
            "xywh: tensor([[739.8075, 633.0853, 139.3708, 486.8358],\n",
            "        [145.1526, 650.0331, 192.0326, 508.1233],\n",
            "        [283.6209, 634.8312, 120.8660, 454.4849],\n",
            "        [402.7171, 474.2405, 800.6132, 492.7648],\n",
            "        [ 39.0143, 712.4948,  78.0287, 322.7491],\n",
            "        [739.3187, 852.4355, 141.3626,  59.1909]])\n",
            "xywhn: tensor([[0.9133, 0.5862, 0.1721, 0.4508],\n",
            "        [0.1792, 0.6019, 0.2371, 0.4705],\n",
            "        [0.3501, 0.5878, 0.1492, 0.4208],\n",
            "        [0.4972, 0.4391, 0.9884, 0.4563],\n",
            "        [0.0482, 0.6597, 0.0963, 0.2988],\n",
            "        [0.9127, 0.7893, 0.1745, 0.0548]])\n",
            "xyxy: tensor([[670.1221, 389.6674, 809.4929, 876.5032],\n",
            "        [ 49.1363, 395.9715, 241.1689, 904.0948],\n",
            "        [223.1879, 407.5888, 344.0539, 862.0737],\n",
            "        [  2.4104, 227.8582, 803.0237, 720.6229],\n",
            "        [  0.0000, 551.1202,  78.0287, 873.8694],\n",
            "        [668.6374, 822.8401, 810.0000, 882.0309]])\n",
            "xyxyn: tensor([[0.8273, 0.3608, 0.9994, 0.8116],\n",
            "        [0.0607, 0.3666, 0.2977, 0.8371],\n",
            "        [0.2755, 0.3774, 0.4248, 0.7982],\n",
            "        [0.0030, 0.2110, 0.9914, 0.6672],\n",
            "        [0.0000, 0.5103, 0.0963, 0.8091],\n",
            "        [0.8255, 0.7619, 1.0000, 0.8167]])\n",
            "(6,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        }
      ]
    }
  ]
}