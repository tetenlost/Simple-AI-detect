{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# resnet18 分類器模型訓練\n",
        "\n",
        "使用pytorch提供之模型進行訓練\n",
        "\n",
        "\n",
        "*   在\"常見CNN分類模型\"中展示了如何使用pytorch提供之模型進行預測(RESNET、VGG等)，但在實際應用上卻較難與需求吻合(如產品瑕疵類別)，因此此篇將使用\"遷移學習\"對模型在訓練，使其可以分類出我們想要之類別\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DBy_UC1ZArkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 下載分類影像\n",
        "\n",
        "\n",
        "*   在製作訓練檔上需要將圖片放置成以下特定格式\n",
        "\n",
        "(此篇教學已先分好了，按下執行就完事)\n",
        "\n",
        "    ```\n",
        "    |-train <- 這是訓練集資料夾\n",
        "     |-cls1 <-類別1的圖像資料夾\n",
        "      |-0000.jpg <-類別1的圖像(圖像名稱可隨意)\n",
        "     |-cls2\n",
        "     .\n",
        "    |-val <-這是測試集資料夾\n",
        "     |-cls1 <-類別1的圖像資料夾\n",
        "      |-0001.jpg\n",
        "     |-cls2\n",
        "    ```"
      ],
      "metadata": {
        "id": "KyqrIC-dGgUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hjJkOirSAj1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a35a0cf-7101-486f-ad9f-f23a88c80c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'demo_training_data'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Total 114 (delta 0), reused 0 (delta 0), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (114/114), 2.17 MiB | 12.30 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tetenlost/demo_training_data.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "K2YY-hPxFHO7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 宣告資料讀取函式\n",
        "\n",
        "* 將資料集打包，並做影像處理，方便後續訓練"
      ],
      "metadata": {
        "id": "IdqflgGCGk8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_data(path,batchsize):\n",
        "    #宣告訓練集影像處理方式\n",
        "    train_transform = transforms.Compose([\n",
        "                        #圖像縮放至224*224\n",
        "                        transforms.Resize((224,224)),\n",
        "                        #影像隨機水平翻轉(機率50%)\n",
        "                        transforms.RandomHorizontalFlip(p=0.5),\n",
        "                        #影像隨機垂直翻轉(機率50%) \n",
        "                        transforms.RandomVerticalFlip(p=0.5),\n",
        "                        #影像之亮度、色相、飽和度隨機轉換\n",
        "                        transforms.ColorJitter(hue=0.3),\n",
        "                        #影像旋轉、平移、縮放\n",
        "                        transforms.RandomAffine(degrees=20, shear=(30,30), translate=(0.2, 0.2)),\n",
        "                        #將影像轉換為pytorch格式\n",
        "                        transforms.ToTensor(),\n",
        "                        #資料標準化至(-1,1)，為了更好的訓練\n",
        "                        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "                        ])\n",
        "    #宣告測試集影像處理方式\n",
        "    val_transform = transforms.Compose([\n",
        "                        #圖像縮放至224*224\n",
        "                        transforms.Resize((224,224)),\n",
        "                        #將影像轉換為pytorch格式\n",
        "                        transforms.ToTensor(),\n",
        "                        #資料標準化至(-1,1)，為了更好的訓練\n",
        "                        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]),\n",
        "                        ])\n",
        "    #使用ImageFolder將圖片與類別作匹配，並添加影像處理\n",
        "    train_datasets = datasets.ImageFolder(os.path.join(path, 'train'), train_transform)\n",
        "    val_datasets = datasets.ImageFolder(os.path.join(path, 'val'), val_transform)\n",
        "    #製作Dataloader，將訓練/測試拆分為batch(如batch_size=16，就是將訓練/測試每16張做為一個batch)\n",
        "    train_dataloaders = torch.utils.data.DataLoader(train_datasets, batch_size=batchsize,shuffle=True, num_workers=4)\n",
        "    val_dataloaders = torch.utils.data.DataLoader(val_datasets, batch_size=batchsize,shuffle=True, num_workers=4)\n",
        "    dataset_sizes={\n",
        "            'train':len(train_datasets),\n",
        "            'val':len(val_datasets)\n",
        "            }\n",
        "    return train_dataloaders,val_dataloaders,dataset_sizes"
      ],
      "metadata": {
        "id": "Pngfj5waJ5WV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 宣告訓練程式"
      ],
      "metadata": {
        "id": "lvDQGdyJMnOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_d, val_d, dataset_sizes, criterion, optimizer, scheduler,device, num_epochs=25):\n",
        "    #計時\n",
        "    since = time.time() \n",
        "    #將訓練/測試Dataloader製作成字典\n",
        "    dataloaders={\n",
        "            'train':train_d,\n",
        "            'val':val_d\n",
        "          }\n",
        "    best_acc = 0.0\n",
        "    #執行迴圈，總次數為訓練次數\n",
        "    for epoch in range(num_epochs):\n",
        "        #顯示幕前的訓練次數\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        #執行迴圈，第一次先執行訓練(train)，在執行測式(val)\n",
        "        for phase in ['train', 'val']:\n",
        "            #如果是執行訓練，開啟訓練模式\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            #如果不是，開啟測試模式  \n",
        "            else:\n",
        "                model.eval() \n",
        "            #初始化本次loss值與正確率\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            #執行迴圈，將批次資料從 dataloader中拿出來做訓練/測試\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                #將圖片放入設備中(CPU/GPU)\n",
        "                inputs = inputs.to(device)\n",
        "                #將答案放入設備中(CPU/GPU)\n",
        "                labels = labels.to(device)\n",
        "                #初始化優化器\n",
        "                optimizer.zero_grad()\n",
        "                #設定是否計算梯度(誤差方向)，關係到模型是否會學習\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #圖像放入模型中進行判定\n",
        "                    outputs = model(inputs)\n",
        "                    #選出得分最高之選項\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    #將輸出與答案比對，計算loss(誤差大小)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    #如果是訓練中，則將梯度(誤差方向)與loss(誤差大小)回傳至模型中，並更新權重\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() \n",
        "                        optimizer.step() \n",
        "                #將此批次訓練的loss(誤差大小)與正確數進行加總\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            #如果為訓練，更新學習率調整器\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            #計算該次訓練的平均正確率&loss\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            #存下最新的model\n",
        "            torch.save(model,'./last_model.pth')\n",
        "\n",
        "            #如果此次結果正確率創下歷史新高，則儲存\n",
        "            if phase == 'val' and epoch_acc >= best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model,'./best_model.pth')\n",
        "\n",
        "    #計算此次訓練浪費多少時間         \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    #顯示最好的那一次結果\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WYljv21UMneO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 宣告主程式(含訓練參數) "
      ],
      "metadata": {
        "id": "CHQt33NgJlrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    #宣告batch size\n",
        "    bs = 16\n",
        "    #宣告訓練資料存放點\n",
        "    path = './demo_training_data'\n",
        "    #宣告訓練次數\n",
        "    epoch = 100    \n",
        "    #取得訓練設備(CPU or GPU)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #獲取官方建構神經網路\n",
        "    model_ft = models.resnet18(pretrained=True)\n",
        "    ##以下是遷移學習\n",
        "    #查看倒數第二層餐數量\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    #將最後一層更改為我們的層(類別數更改)\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "    ##遷移學習更改部分結束\n",
        "    #將模型放入訓練設備(CPU or GPU)\n",
        "    model_ft.to(device)\n",
        "    #建立圖像資料集\n",
        "    train_d,val_d, dsl= build_data(path,bs)\n",
        "    #宣告損失函數\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #宣告優化器\n",
        "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "    #宣告學習率調整器(每隔一段時間將學習率縮小，以習得更好的權重)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\n",
        "    #將上述宣告的東西放進訓練函式中訓練\n",
        "    train_model(model_ft,train_d,val_d,dsl,criterion, optimizer_ft, exp_lr_scheduler,device, num_epochs=epoch)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "USX0EgfKNGDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}